{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network for Text Classification\n",
    "In this tutorial, we are going to implement a convolutional neural network to classify movie review dataset(positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import preprocess \n",
    "from model import TextCNN\n",
    "from sklearn.cross_validation import train_test_split\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_pos = open('data/polarity/pos.txt').readlines()\n",
    "x_neg = open('data/polarity/neg.txt').readlines()\n",
    "y_pos = np.ones(len(x_pos))\n",
    "y_neg = np.zeros(len(x_neg))\n",
    "y = np.concatenate([y_pos, y_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5331\n",
      "5331\n",
      "if you sometimes like to go to the movies to have fun , wasabi is a good place to start . \n",
      "\n",
      "simplistic , silly and tedious . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (len(x_pos))\n",
    "print (len(x_neg))\n",
    "print (x_pos[3])\n",
    "print (x_neg[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, mask, word_to_idx, seq_length, vocab_size = preprocess(x_pos+x_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8529, 58)\n",
      "(2133, 58)\n",
      "(8529,)\n",
      "(2133,)\n"
     ]
    }
   ],
   "source": [
    "# randomly shuffle data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=TextCNN(batch_size=100, seq_length=seq_length, num_class=2, vocab_size=vocab_size, \n",
    "                 dim_emb=128, filter_sizes=[2,3,4], num_filters=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1] Step: [1/85] loss: [0.575043] accuracy: [0.900000]\n",
      "model/textcnn-1-1 saved\n",
      "Epoch: [1] Step: [11/85] loss: [0.653879] accuracy: [0.640000]\n",
      "Epoch: [1] Step: [21/85] loss: [0.660412] accuracy: [0.610000]\n",
      "Epoch: [1] Step: [31/85] loss: [0.658146] accuracy: [0.640000]\n",
      "Epoch: [1] Step: [41/85] loss: [0.634064] accuracy: [0.640000]\n",
      "Epoch: [1] Step: [51/85] loss: [0.622959] accuracy: [0.680000]\n",
      "Epoch: [1] Step: [61/85] loss: [0.599468] accuracy: [0.710000]\n",
      "Epoch: [1] Step: [71/85] loss: [0.567238] accuracy: [0.760000]\n",
      "Epoch: [1] Step: [81/85] loss: [0.645155] accuracy: [0.660000]\n",
      "Epoch: [2] Step: [1/85] loss: [0.518303] accuracy: [0.810000]\n",
      "model/textcnn-2-1 saved\n",
      "Epoch: [2] Step: [11/85] loss: [0.549249] accuracy: [0.790000]\n",
      "Epoch: [2] Step: [21/85] loss: [0.538894] accuracy: [0.770000]\n",
      "Epoch: [2] Step: [31/85] loss: [0.555874] accuracy: [0.770000]\n",
      "Epoch: [2] Step: [41/85] loss: [0.517703] accuracy: [0.810000]\n",
      "Epoch: [2] Step: [51/85] loss: [0.483076] accuracy: [0.780000]\n",
      "Epoch: [2] Step: [61/85] loss: [0.451871] accuracy: [0.840000]\n",
      "Epoch: [2] Step: [71/85] loss: [0.454883] accuracy: [0.820000]\n",
      "Epoch: [2] Step: [81/85] loss: [0.506673] accuracy: [0.800000]\n",
      "Epoch: [3] Step: [1/85] loss: [0.403764] accuracy: [0.840000]\n",
      "model/textcnn-3-1 saved\n",
      "Epoch: [3] Step: [11/85] loss: [0.413578] accuracy: [0.810000]\n",
      "Epoch: [3] Step: [21/85] loss: [0.403397] accuracy: [0.870000]\n",
      "Epoch: [3] Step: [31/85] loss: [0.449975] accuracy: [0.820000]\n",
      "Epoch: [3] Step: [41/85] loss: [0.401848] accuracy: [0.870000]\n",
      "Epoch: [3] Step: [51/85] loss: [0.344028] accuracy: [0.910000]\n",
      "Epoch: [3] Step: [61/85] loss: [0.314939] accuracy: [0.920000]\n",
      "Epoch: [3] Step: [71/85] loss: [0.307275] accuracy: [0.930000]\n",
      "Epoch: [3] Step: [81/85] loss: [0.354005] accuracy: [0.910000]\n",
      "Epoch: [4] Step: [1/85] loss: [0.287874] accuracy: [0.890000]\n",
      "model/textcnn-4-1 saved\n",
      "Epoch: [4] Step: [11/85] loss: [0.276245] accuracy: [0.910000]\n",
      "Epoch: [4] Step: [21/85] loss: [0.271077] accuracy: [0.930000]\n",
      "Epoch: [4] Step: [31/85] loss: [0.319969] accuracy: [0.910000]\n",
      "Epoch: [4] Step: [41/85] loss: [0.279780] accuracy: [0.910000]\n",
      "Epoch: [4] Step: [51/85] loss: [0.225074] accuracy: [0.970000]\n",
      "Epoch: [4] Step: [61/85] loss: [0.198654] accuracy: [0.950000]\n",
      "Epoch: [4] Step: [71/85] loss: [0.182900] accuracy: [0.980000]\n",
      "Epoch: [4] Step: [81/85] loss: [0.219142] accuracy: [0.960000]\n",
      "Epoch: [5] Step: [1/85] loss: [0.182873] accuracy: [0.950000]\n",
      "model/textcnn-5-1 saved\n",
      "Epoch: [5] Step: [11/85] loss: [0.158682] accuracy: [0.980000]\n",
      "Epoch: [5] Step: [21/85] loss: [0.162846] accuracy: [0.980000]\n",
      "Epoch: [5] Step: [31/85] loss: [0.202675] accuracy: [0.950000]\n",
      "Epoch: [5] Step: [41/85] loss: [0.176975] accuracy: [0.960000]\n",
      "Epoch: [5] Step: [51/85] loss: [0.131766] accuracy: [1.000000]\n",
      "Epoch: [5] Step: [61/85] loss: [0.113523] accuracy: [0.990000]\n",
      "Epoch: [5] Step: [71/85] loss: [0.101592] accuracy: [1.000000]\n",
      "Epoch: [5] Step: [81/85] loss: [0.132211] accuracy: [0.980000]\n",
      "Test accuracy: 0.717\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 5\n",
    "batch_size = 100\n",
    "num_iter_per_epoch = x_train.shape[0] / batch_size\n",
    "log_path = 'log/'\n",
    "model_save_path = 'model/'\n",
    "\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path)\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.makedirs(model_save_path)\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    # initialize parameters\n",
    "    tf.initialize_all_variables().run()\n",
    "    summary_writer = tf.train.SummaryWriter(logdir=log_path, graph=tf.get_default_graph())\n",
    "\n",
    "    for e in range(num_epoch):\n",
    "        for i in range(num_iter_per_epoch):\n",
    "            # train the discriminator\n",
    "            x_batch = x_train[i*batch_size:(i+1)*batch_size]\n",
    "            y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
    "            feed_dict = {model.x: x_batch, model.y: y_batch}\n",
    "            sess.run(model.train_op, feed_dict)\n",
    "\n",
    "            \n",
    "\n",
    "            if i % 10 == 0:\n",
    "                summary, loss, acc = sess.run([model.summary_op, model.loss, model.accuracy], feed_dict)\n",
    "                summary_writer.add_summary(summary, e*num_iter_per_epoch + i)\n",
    "                print ('Epoch: [%d] Step: [%d/%d] loss: [%.6f] accuracy: [%.6f]' %(e+1, i+1, num_iter_per_epoch, loss, acc))\n",
    "\n",
    "            if i % 500 == 0:  \n",
    "                model.saver.save(sess, os.path.join(model_save_path, 'textcnn-%d' %(e+1)), global_step=i+1) \n",
    "                print ('model/textcnn-%d-%d saved' %(e+1, i+1))\n",
    "                \n",
    "                \n",
    "    \n",
    "    num_iter_per_epoch = int(x_test.shape[0] / batch_size)\n",
    "    test_accuracy = 0.0\n",
    "    for i in range(num_iter_per_epoch):\n",
    "        x_batch = x_test[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = y_test[i*batch_size:(i+1)*batch_size]\n",
    "        acc = sess.run(model.accuracy, feed_dict={model.x: x_batch, model.y: y_batch})\n",
    "        test_accuracy += acc\n",
    "\n",
    "    print (\"Test accuracy: %.3f\" %(test_accuracy/num_iter_per_epoch))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
